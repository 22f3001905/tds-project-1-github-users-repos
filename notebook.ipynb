{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import requests\n",
    "import requests_cache\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import linregress\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GitHub User Data Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing GH Search API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://api.github.com/search/users\"\n",
    "\n",
    "params = {\n",
    "    'q': 'followers:>100 location:Toronto',  # Uses a query string (GraphQL).\n",
    "    'per_page': 100,\n",
    "    'page': 1\n",
    "}\n",
    "# Authenticated Users: 5,000 requests per hour.\n",
    "access_token = os.getenv('GITHUB_TOKEN')\n",
    "headers = {'Authorization': f'token {access_token}'}\n",
    "\n",
    "response = requests.get(url, params=params, headers=headers)\n",
    "print('URL:', response.url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    print('# users:', len(data['items']))\n",
    "else:\n",
    "    print(f\"Failed to fetch data. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.links  # feature of requests library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['items'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search for Users\n",
    "\n",
    "* Toronto users with more than 100 followers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dynamic_delay(response):\n",
    "    if response.headers.get('X-RateLimit-Remaining') == '0':\n",
    "        reset_time = int(response.headers.get('X-RateLimit-Reset'))\n",
    "        sleep_time = reset_time - int(time.time()) + 5  # Add a buffer of 5s.\n",
    "\n",
    "        print(f\"Rate limit exceeded. Sleeping for {sleep_time} seconds!\")\n",
    "        time.sleep(sleep_time)\n",
    "\n",
    "    time.sleep(1)  # Sleep for 1s regardless."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printed_message_from_cached = False\n",
    "requests_cache.install_cache('cache/search_users', expire_after=None)\n",
    "\n",
    "users = []  # All users in Toronto with more than 100 followers.\n",
    "\n",
    "url = \"https://api.github.com/search/users\"\n",
    "params = {\n",
    "    'q': 'followers:>100 location:Toronto',  # Uses a query string (GraphQL).\n",
    "    'per_page': 100,\n",
    "    'page': 1\n",
    "}\n",
    "\n",
    "access_token = os.getenv('GITHUB_TOKEN')\n",
    "headers = {'Authorization': f'token {access_token}'}\n",
    "\n",
    "while True:\n",
    "    response = requests.get(url, params=params, headers=headers)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to fetch users. Status code: {response.status_code}\")\n",
    "        break\n",
    "\n",
    "    data = response.json()\n",
    "\n",
    "    for user in data.get('items', []):\n",
    "        users.append({\n",
    "            'login': user['login'],\n",
    "            'id': user['id'],\n",
    "            'url': user['url'],\n",
    "            'repos_url': user['repos_url']\n",
    "        })\n",
    "    \n",
    "    if response.from_cache:\n",
    "        if not printed_message_from_cached:\n",
    "            print('Fetched from cache.')\n",
    "            printed_message_from_cached = True\n",
    "    else:\n",
    "        print(\"Fetched from API:\", response.url)\n",
    "        dynamic_delay(response)\n",
    "\n",
    "    # Check if there are more pages.\n",
    "    if 'next' not in response.links:\n",
    "        break\n",
    "\n",
    "    params['page'] += 1\n",
    "\n",
    "print('# of users:', len(users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict(response.headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch User Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_company_name(company):\n",
    "    company_name = None\n",
    "    if company:\n",
    "        company_name = company.strip()\n",
    "        if company_name.startswith('@'):\n",
    "            company_name = company_name[1:]\n",
    "        company_name = company_name.upper()\n",
    "    \n",
    "    return company_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printed_message_from_cached = False\n",
    "requests_cache.install_cache('cache/users', expire_after=None)\n",
    "\n",
    "users_data = []\n",
    "\n",
    "for user in users:\n",
    "    response = requests.get(user['url'], headers=headers)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to fetch {user['login']}'s data. Status code: {response.status_code}\")\n",
    "        break\n",
    "    \n",
    "    data = response.json()\n",
    "    \n",
    "    users_data.append({\n",
    "        'login': data['login'],\n",
    "        'name': data['name'],\n",
    "        'company': clean_company_name(data['company']),\n",
    "        'location': data['location'],\n",
    "        'email': data['email'],\n",
    "        'hireable': data['hireable'],\n",
    "        'bio': data['bio'],\n",
    "        'public_repos': data['public_repos'],\n",
    "        'followers': data['followers'],\n",
    "        'following': data['following'],\n",
    "        'created_at': data['created_at'],\n",
    "    })\n",
    "\n",
    "    if response.from_cache:\n",
    "        if not printed_message_from_cached:\n",
    "            print('Fetched from cache.')\n",
    "            printed_message_from_cached = True\n",
    "    else:\n",
    "        print('Fetched from API:', response.url)\n",
    "        dynamic_delay(response)\n",
    "\n",
    "users_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(users_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict(response.headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save user data to .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_df = pd.DataFrame(users_data)\n",
    "users_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_number_of_repos_expected = users_df[users_df['public_repos'] <= 500]['public_repos'].sum() + (500 * len(users_df[users_df['public_repos'] > 500]))\n",
    "print(f\"Total Expected Repos: {total_number_of_repos_expected}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_unique_users = len(users_df['login'].unique())  # Sanity check.\n",
    "print(f\"# of unique users: {n_unique_users}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_df.to_csv('users.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch Users' Repo Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printed_message_from_cached = False\n",
    "requests_cache.install_cache('cache/repos', expire_after=None)\n",
    "\n",
    "repos_data = []\n",
    "\n",
    "for user in users:\n",
    "    repos = []\n",
    "    params = {\n",
    "        'sort': 'pushed',\n",
    "        'direction': 'desc',\n",
    "        'per_page': 100,\n",
    "        'page': 1,\n",
    "    }\n",
    "    while True:\n",
    "        response = requests.get(user['repos_url'], params=params, headers=headers)\n",
    "\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Failed to fetch { user['login'] }'s repo data. Status code: {response.status_code}\")\n",
    "            break\n",
    "        \n",
    "        data = response.json()\n",
    "        for repo in data:\n",
    "            repos.append({\n",
    "                'login': user['login'],\n",
    "                'full_name': repo['full_name'],\n",
    "                'created_at': repo['created_at'],\n",
    "                'stargazers_count': repo['stargazers_count'],\n",
    "                'watchers_count': repo['watchers_count'],\n",
    "                'language': repo['language'],\n",
    "                'has_projects': repo['has_projects'],\n",
    "                'has_wiki': repo['has_wiki'],\n",
    "                'license_name': repo['license']['key'] if repo['license'] else None,\n",
    "            })\n",
    "        \n",
    "        if response.from_cache:\n",
    "            if not printed_message_from_cached:\n",
    "                print('Fetched from cache.')\n",
    "                printed_message_from_cached = True\n",
    "        else:\n",
    "            print('Fetched from API:', response.url)\n",
    "            dynamic_delay(response)\n",
    "\n",
    "        if ('next' not in response.links) or (params['page'] == 5):\n",
    "            break\n",
    "\n",
    "        params['page'] += 1\n",
    "    \n",
    "    repos_data.extend(repos)\n",
    "\n",
    "print('# of Repos:', len(repos_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Pass repos sanity check:', total_number_of_repos_expected == len(repos_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repos_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save repo data to .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repos_df = pd.DataFrame(repos_data)\n",
    "repos_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repos_df.to_csv('repositories.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. Who are the top 5 users in Toronto with the highest number of followers? List their login in order, comma-separated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "','.join(users_df.nlargest(n=5, columns='followers')['login'].to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2. Who are the 5 earliest registered GitHub users in Toronto? List their login in ascending order of created_at, comma-separated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_df['created_at'] = pd.to_datetime(users_df['created_at'])\n",
    "users_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oldest_users = users_df.iloc[users_df['created_at'].sort_values(ascending=True).index[:5].to_list()]['login'].to_list()\n",
    "','.join(sorted(oldest_users))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3. What are the 3 most popular license among these users? Ignore missing licenses. List the license_name in order, comma-separated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repos_df['created_at'] = pd.to_datetime(repos_df['created_at'])\n",
    "repos_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "','.join(repos_df['license_name'].value_counts(dropna=True).index[:3].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repos_df['license_name'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4. Which company do the majority of these developers work at?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_df['company'].value_counts().index[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5. Which programming language is most popular among these users?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repos_df['language'].value_counts().index[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6. Which programming language is the second most popular among users who joined after 2020?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = repos_df.merge(users_df, how='inner', on='login', suffixes=('_repo', '_user'))\n",
    "merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_df[users_df['created_at'].dt.year > 2020]['public_repos'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged[merged['created_at_user'].dt.year > 2020]['language'].value_counts().index[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q7. Which language has the highest average number of stars per repository?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repos_df.groupby('language')['stargazers_count'].mean().sort_values(ascending=False).index[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q8. Let's define `leader_strength` as `followers / (1 + following)`. Who are the top 5 in terms of `leader_strength`? List their login in order, comma-separated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strong_leaders_idx = (users_df['followers'] / (1 + users_df['following'])).sort_values(ascending=False).index[:5]\n",
    "\n",
    "','.join(users_df.loc[strong_leaders_idx, 'login'].to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q9. What is the correlation between the number of followers and the number of public repositories among users in Toronto?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_df['followers'].corr(users_df['public_repos']).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q10. Does creating more repos help users get more followers? Using regression, estimate how many additional followers a user gets per additional public repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_df[['public_repos', 'followers']].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linregress(users_df['public_repos'], users_df['followers']).slope.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q11. Do people typically enable projects and wikis together? What is the correlation between a repo having projects enabled and having wiki enabled?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repos_df[['has_projects', 'has_wiki']].corr().iloc[0, 1].round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q12. Do hireable users follow more people than those who are not hireable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_df['hireable'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_df[users_df['hireable'] == True]['following'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_df[users_df['hireable'] != True]['following'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(users_df[users_df['hireable'] == True]['following'].mean() - users_df[users_df['hireable'] != True]['following'].mean()).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q13. Some developers write long bios. Does that help them get more followers? What's the correlation of the length of their bio (in Unicode characters) with followers? (Ignore people without bios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_with_bio = users_df.loc[~users_df['bio'].isna(), :].copy()\n",
    "users_with_bio['bio_length'] = users_with_bio['bio'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linregress(users_with_bio['bio_length'], users_with_bio['followers']).slope.round(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
